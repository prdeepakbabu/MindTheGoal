# ğŸ¯ MindTheGoal

[![arXiv](https://img.shields.io/badge/arXiv-2510.03696-b31b1b.svg)](https://arxiv.org/abs/2510.03696)
[![Paper](https://img.shields.io/badge/ğŸ“„_Paper-Mind_The_Goal-blue)](https://arxiv.org/abs/2510.03696)

**Data-Efficient Goal-Oriented Evaluation of Conversational Agents and Chatbots using Teacher Models**

> ğŸ“š **Based on:** Piskala, D.B., Chen, S., Patel, U., Kalra, P., & Castrillo, R. (2025). *"Mind the Goal: Data-Efficient Goal-Oriented Evaluation of Conversational Agents and Chatbots using Teacher Models"* [[arXiv:2510.03696](https://arxiv.org/abs/2510.03696)]

A comprehensive implementation of the MindTheGoal framework for evaluating multi-turn conversational agents at the **goal level** rather than turn level.

---

## ğŸ“‹ Overview

Traditional chatbot evaluation focuses on individual turns, missing whether users actually achieved their goals. MindTheGoal addresses this by:

1. **Goal Segmentation**: Detecting when users start new goals vs. continue previous ones
2. **Goal Success Rate (GSR)**: Measuring the percentage of fulfilled goals (strict: all turns must succeed)
3. **Root Cause of Failure (RCOF)**: Categorizing failures into 7 actionable error types

## âœ¨ Features

- **Batch Evaluation**: Process multi-turn conversation datasets (MultiWOZ, custom datasets)
- **Interactive Chat**: Converse with an LLM agent while viewing real-time evaluation
- **Live Judge Panel**: See LLM-as-judge output with thinking tokens as you chat
- **GSR Dashboard**: Visualize goal success rates and RCOF distributions
- **AWS Bedrock Integration**: Uses Claude 3.5 Sonnet for chat and evaluation

---

## ğŸ“¸ Screenshots

### Evaluation Dashboard
View overall GSR metrics, RCOF distribution charts, and detailed session results.

![Dashboard](images/dashboard.png)

### Run Evaluation
Start new evaluations on MultiWOZ or custom datasets with configurable sample sizes.

![Evaluation](images/evaluation.png)

### Dialog Viewer
Inspect individual conversation sessions with goal segmentation and turn-level evaluation.

![Viewer](images/viewer.png)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend (React)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Chat Interface  â”‚  â”‚  Judge Panel    â”‚  â”‚ GSR Dashboard   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ WebSocket          â”‚ REST               â”‚ REST
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           â–¼                    â–¼                    â–¼           â”‚
â”‚                      FastAPI Backend                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    API Layer                            â”‚    â”‚
â”‚  â”‚  /chat (WebSocket)  â”‚  /evaluate  â”‚  /datasets          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚             â”‚                 â”‚                â”‚                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                   Core Framework                        â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚Goal Segment. â”‚ â”‚GSR Calculat.â”‚ â”‚RCOF Classifier   â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                            â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              LLM Layer (AWS Bedrock)                    â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚   Chat Agent    â”‚    â”‚     Judge Agent         â”‚     â”‚    â”‚
â”‚  â”‚  â”‚ (Claude Sonnet) â”‚    â”‚ (Claude Sonnet + CoT)   â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ Key Concepts

### Goal Success Rate (GSR)

A goal is successful **only if ALL its turns are successful**:

```
GSR = (Successful Goals / Total Goals) Ã— 100%
```

### Root Cause of Failure (RCOF) Taxonomy

| Code | Category | Description |
|------|----------|-------------|
| E1 | Language Understanding | Misunderstood user's request or context |
| E2 | Refusal to Answer | Inappropriate refusal despite ability to help |
| E3 | Incorrect Retrieval | Retrieved wrong information (RAG issue) |
| E4 | Retrieval Failure | Failed to retrieve any relevant information |
| E5 | System Error | Technical issues (timeout, truncation) |
| E6 | Incorrect Routing | Query routed to wrong domain/module |
| E7 | Out-of-Domain | Request outside system's designed scope |

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Node.js 18+ (for frontend)
- AWS Account with Bedrock access (Claude 3.7 Sonnet)

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/MindTheGoal.git
cd MindTheGoal

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install Python dependencies
pip install -r requirements.txt

# Configure AWS credentials
cp .env.example .env
# Edit .env with your AWS configuration

# Install frontend dependencies
cd frontend
npm install
cd ..
```

### Configure AWS

```bash
# Option 1: AWS CLI configuration
aws configure

# Option 2: Environment variables in .env
AWS_REGION=us-west-2
AWS_PROFILE=default
```

### Run the Application

```bash
# Start the backend server
python run_web.py

# In a new terminal, start the frontend
cd frontend
npm run dev
```

Visit `http://localhost:3000` to access the UI.

---

## ğŸ“Š Usage

### 1. Interactive Chat with Live Evaluation

1. Open the web interface
2. Start chatting with the agent
3. Watch the Judge Panel for real-time evaluation:
   - Goal segmentation (when new goals are detected)
   - Turn quality assessment (success/failure)
   - RCOF classification for failures
   - Running GSR calculation

### 2. Batch Dataset Evaluation

```bash
# Evaluate MultiWOZ dataset
python main.py evaluate --dataset multiwoz --sample 100

# Evaluate custom dataset
python main.py evaluate --dataset custom --path ./my_conversations.json
```

### 3. API Endpoints

```bash
# Start evaluation job
POST /api/evaluate
{
  "dataset": "multiwoz",
  "sample_size": 100
}

# Get evaluation results
GET /api/evaluate/{job_id}/results

# Chat with live judging (WebSocket)
WS /api/chat
```

---

## ğŸ“ Project Structure

```
MindTheGoal/
â”œâ”€â”€ config.py                  # Configuration management
â”œâ”€â”€ main.py                    # CLI entry point
â”œâ”€â”€ run_web.py                 # Web server entry point
â”œâ”€â”€ requirements.txt           # Python dependencies
â”‚
â”œâ”€â”€ core/                      # Paper implementation
â”‚   â”œâ”€â”€ models.py              # Session, Goal, Turn dataclasses
â”‚   â”œâ”€â”€ goal_segmentation.py   # Goal boundary detection
â”‚   â”œâ”€â”€ turn_evaluator.py      # Turn quality assessment
â”‚   â”œâ”€â”€ gsr_calculator.py      # GSR computation
â”‚   â””â”€â”€ rcof_classifier.py     # E1-E7 taxonomy
â”‚
â”œâ”€â”€ llm/                       # LLM integration
â”‚   â”œâ”€â”€ bedrock_client.py      # AWS Bedrock wrapper
â”‚   â”œâ”€â”€ judge_agent.py         # LLM-as-judge
â”‚   â”œâ”€â”€ chat_agent.py          # Conversational agent
â”‚   â””â”€â”€ prompts.py             # All LLM prompts
â”‚
â”œâ”€â”€ datasets/                  # Dataset management
â”‚   â”œâ”€â”€ multiwoz_loader.py     # MultiWOZ parser
â”‚   â””â”€â”€ data/                  # Dataset files
â”‚
â”œâ”€â”€ evaluation/                # Batch evaluation
â”‚   â”œâ”€â”€ batch_evaluator.py     # Process batches
â”‚   â””â”€â”€ report_generator.py    # Generate reports
â”‚
â”œâ”€â”€ web/                       # FastAPI backend
â”‚   â”œâ”€â”€ app.py                 # FastAPI application
â”‚   â””â”€â”€ api/                   # API endpoints
â”‚
â”œâ”€â”€ frontend/                  # React UI
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ components/
â”‚           â”œâ”€â”€ ChatInterface.tsx
â”‚           â”œâ”€â”€ JudgePanel.tsx
â”‚           â””â”€â”€ GSRDashboard.tsx
â”‚
â””â”€â”€ tests/                     # Test suite
```

---

## ğŸ§ª Datasets

### Supported Datasets

| Dataset | Description | Size | Domains |
|---------|-------------|------|---------|
| **MultiWOZ 2.4** | Task-oriented dialogues | ~10K dialogues | Restaurant, Hotel, Taxi, Train, Attraction |
| **Custom JSON** | Your own conversations | Variable | Custom |

### Custom Dataset Format

```json
{
  "dialogues": [
    {
      "dialogue_id": "conv_001",
      "turns": [
        {
          "turn_id": 1,
          "user": "I need a restaurant in the center of town",
          "system": "I found several restaurants. What cuisine do you prefer?"
        },
        {
          "turn_id": 2,
          "user": "Italian please",
          "system": "I recommend 'Pasta Palace' at 123 Main St. Would you like to book?"
        }
      ]
    }
  ]
}
```

---

## ğŸ“ˆ Sample Output

### GSR Report

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    MindTheGoal Evaluation Report
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Dataset: MultiWOZ 2.4 (100 dialogues)
Evaluation Date: 2026-01-23

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                         Summary Metrics
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Total Dialogues:        100
Total Goals:            287
Total Turns:            1,432

Overall GSR:            72.3%
Single-turn GSR:        81.2%
Multi-turn GSR:         65.8%

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    Root Cause of Failure (RCOF)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

E4 - Retrieval Failure:        35.2%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
E1 - Language Understanding:   27.8%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
E3 - Incorrect Retrieval:      18.1%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
E5 - System Error:             11.3%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
E2 - Refusal to Answer:         4.9%  â–ˆâ–ˆ
E6 - Incorrect Routing:         2.7%  â–ˆ
E7 - Out-of-Domain:             0.0%  

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ”§ Configuration

### Customizing RCOF Categories

The RCOF (Root Cause of Failure) taxonomy can be customized for your use case. Edit `config/rcof_config.json`:

```json
{
  "rcof_categories": [
    {
      "code": "E1",
      "name": "Language Understanding",
      "description": "Agent misunderstood user's request, context, or intent",
      "examples": ["Misinterpreting a booking request", "Wrong entity extraction"]
    },
    {
      "code": "E8",
      "name": "Custom Category",
      "description": "Your custom failure category for domain-specific errors",
      "examples": ["Example 1", "Example 2"]
    }
  ]
}
```

You can:
- **Add new categories**: Define domain-specific failure types (E8, E9, etc.)
- **Modify descriptions**: Tailor to your specific use case
- **Update examples**: Provide relevant examples for your domain
- **Remove categories**: Comment out categories that don't apply

The Settings page (`/settings`) also provides a UI to edit these configurations.

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `AWS_REGION` | AWS region for Bedrock | `us-west-2` |
| `AWS_PROFILE` | AWS credentials profile | `default` |
| `BEDROCK_MODEL_ID` | Claude model ID | `anthropic.claude-3-5-sonnet-20241022-v2:0` |
| `JUDGE_TEMPERATURE` | Temperature for judge | `0.1` |
| `CHAT_TEMPERATURE` | Temperature for chat agent | `0.7` |
| `MAX_TOKENS` | Max tokens per response | `4096` |
| `LOG_LEVEL` | Logging level | `INFO` |

---

## ğŸ“– Citation

If you use this implementation, please cite the original paper:

```bibtex
@misc{piskala2025mindgoaldataefficientgoaloriented,
      title={Mind the Goal: Data-Efficient Goal-Oriented Evaluation of Conversational Agents and Chatbots using Teacher Models}, 
      author={Deepak Babu Piskala and Sharlene Chen and Udita Patel and Parul Kalra and Rafael Castrillo},
      year={2025},
      eprint={2510.03696},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2510.03696}, 
}
```

---

## ğŸ“š References

- **Paper**: [Mind the Goal: Data-Efficient Goal-Oriented Evaluation of Conversational Agents and Chatbots using Teacher Models](https://arxiv.org/abs/2510.03696)
- **MultiWOZ**: [Multi-Domain Wizard-of-Oz Dataset](https://github.com/budzianowski/multiwoz)
- **AWS Bedrock**: [Amazon Bedrock Documentation](https://docs.aws.amazon.com/bedrock/)

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines before submitting PRs.

---

*Inspired by the MindTheGoal paper from Amazon.com*
